---
layout: post
title: "PytorchバインディングのRustクレート『tch』の紹介"
description: GNN
tags: 深層学習 論文読み
---

　Rustでも深層学習ライブラリを使用したいのですが、Rustネイティブの有名なクレートがまだありません。tch-rsはタイトル通り、pytorchのC++ライブラリである『Libtorch』をRustから呼び出して使用しています。ですので、Pythonライブラリと完全互換性がないため注意が必要です。

## tch-rsのインストール[^tch-rs-url]

　主にgithubのREADMEにかかれていることを実行すれば使用できます。まずはLibtorchをダウンロードして展開し、`LD_LIBRARY_PATH`にpathを通します。例ではGPU版をインストールしていますが、CPUのみで十分な場合はCPU版をインストールしてください。以下のサンプルコードはディレクトリの指定は特にしていませんが、実際に作業を行う際はディレクトリ管理に注意してください。[^dict]

```shell
$ curl -O https://download.pytorch.org/libtorch/cu102/libtorch-cxx11-abi-shared-with-deps-1.5.0.zip
$ unzip libtorch-cxx11-abi-shared-with-deps-1.5.0.zip
$ export LD_LIBRARY_PATH=$PWD/libtorch/lib:$LD_LIBRARY_PATH
```
## 簡単なスクリプトの実行

```shell
$ cargo new --bin tch-test
```
でプロジェクトを作成し、生成された`Cargo.toml`を以下を追記します。

```toml
[dependencies]
tch = "0.1.5"
```

`src/main.rs`を編集し、サンプルを用意します。

```rust
extern crate tch;
use tch::Tensor;

fn main() {
    let t = Tensor::of_slice(&[3, 1, 4, 1, 5]);
    let t = t * 2;
    t.print();
}
```

最後に

```
$ cargo run
```

で実行できるかを確認します。

## GPUの使用について

主にサンプルプログラムとドキュメントとにらめっこして、使用方法を探ります。以下のコードで簡単にGPUが使用できるかどうかを確認できます。

```rust
extern crate tch;
use tch::Device;

fn main() {
    let t = Tensor::of_slice(&[3, 1, 4, 1, 5]);
    let device = Device::Cuda(1);
    let t = t.to(device);
    t.print();
}
```

このとき、存在しないデバイスのIDを使用するとRUNTIME_ERRORとなります。正常に割り当てられていれば、
```
 3
 1
 4
 1
 5
[ CUDAIntType{5} ]
```
のように出力されます。

---

[^gpu]: そもそもcudaを使うのにいいクレートが見つからない。
[^tch-rs-url]: [tch-rs](https://github.com/LaurentMazare/tch-rs)
[^dict]: ディレクトリ迷子になることはよくあることです...。
